<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="Tal Peretz" />
    <meta name="description" content="Read my latest blog posts on web development, design, and the internet.">
    <link rel="stylesheet" href="../../Main.css">
    <link rel="stylesheet" href="../../Writing.css">
    <script src="../../Main.js"></script>
    <script src="../../Writing.js"></script>
    <title>Blog 10</title>
</head>

<body>
    <header>
        <div class="top-header">
            <a href="../../index.html"><img src="../../NavBar.png" alt="Website Main Logo"></a>
            
            <nav class="navbar">
                <ul>
                <li><a href="../../Portfolio/index.html">Portfolio</a></li>
                <li><a href="../../Designs/index.html">Designs</a></li>
                <li><a href="../index.html">Blogs</a></li>
                <li><a href="../../Essays/index.html">Essays</a></li>
                <li><a href="../../Contact/index.html">Contact</a></li>
                </ul>
            </nav>
        </div>

        <h1>Blog 10</h1>
    </header>
    
    <main>
        <section class="h-entry">
            <article>
            <h2 class="p-name">What does an Ethical Internet Look Like to Me?</h2>
            <time class="dt-published" datetime="2025-05-14">14 May</time>
                <div class="e-content">
                    <h3>The Internet's Ethical Dilemma</h3>
                    <p>
                        The internet exists in a strange form of irony. It was once imagined as a free, open social space - a tool to improve life for everyone. But over time, it has become both a space of opportunity and one of exploitation. To me, the internet still feels mostly ethical - but it is polluted by practices and platforms that prioritise profit over people. As someone who uses the internet daily and studies technology in all different forms, I've seen its potential for creativity and connection, but I've also seen manipulation, misinformation, and exclusion prevail.
                    </p>

                    <h3>Platforms, Power, and Responsibility</h3>
                    <p>
                        Take YouTube, for instance. On the surface, it offers a democratic platform where anyone can share their work. But under that layer lies a network of complex algorithms, targeted ads, and content moderation rules that can unfairly limit speech or increase harmful material. Orgad (2007) frames this tension by describing the internet as part of a global “media environment,” where how we use resources like digital platforms can either “pollute the media environment or contribute to its health”. The ethical stakes are high - and not just for those who build the internet, but for everyone who uses it.
                        I feel personally safe online, but I also recognise that this is a privilege - one shaped by my own experience and knowledge of the internet. Others aren't so lucky. Phishing scams, doxxing, hate speech, and algorithmic manipulation are everyday realities for many users. Orgad reminds us that an ethical media space depends on “proper distance”: a sense of moral responsibility to others we may never meet. This “duty of care” is rarely practiced by platforms that profit from attention rather than accountability.
                        That said, the idea of a perfectly ethical internet is, perhaps, as utopian as a perfect world. My ideal online space would be inclusive, accessible to all, and moderated with compassion. But moderation itself is complicated. Papacharissi (2002) argues that the internet is “a new public space for politically oriented conversation,” but questions whether it can truly become a public sphere - a space for “rational discourse” that promotes democratic ideals. She notes that while the internet connects people across borders, “it frequently fragmentises political discourse” and reproduces existing inequalities. This is especially visible in online communities where elite or well-funded voices dominate, and marginal perspectives struggle to break through. Bias is an innate part of every human being; thus, it is also a part of everything which human beings create. That is why I believe that there can never be a truly ethical internet, only one in which human beings uplift and empower each other with absolutely no malicious intent.
                        As a game design and engineering student, I've also seen ethical issues emerge in gaming culture. Matchmaking algorithms can promote unfair outcomes, chat systems often fail to curb toxicity, and data collection is rampant. These problems reflect a broader digital ecosystem where user experience is often secondary to engagement  or monetisation. We need more than surface-level fixes - we need ethical design principles built into the very architecture of our platforms.
                        So who should be responsible for shaping the chosen ethics of the internet? I don't believe in a universal regulator - that's unrealistic and dangerous. Instead, I think that in an ideal internet, platform owners should take responsibility for what happens in their space, just as users must choose which platforms they support. I think this is the most ideal state for an ethical internet as having a single universal regulator would be the equivalent of a dictatorial state in which a single person or organisation can completely project their own bias onto the rest of the world, regardless of their moral or ethical values. Stein (2008) highlights the danger of assuming we have free speech online when in reality, “speech rights depend largely on the ownership and control of the space in which communication occurs”. She warns that, legally, the internet “has not been recognised as a public space” in which citizens hold meaningful rights. This means we're essentially guests in corporate spaces - subject to the rules of those who profit from our presence. I think that this is an incredibly powerful 'illusion' to which many people become slaves.
                    </p>

                    <h3>Algorithms and the Illusion of Choice</h3>
                    <p>
                        Algorithmic ethics is another terrifying issue. By design, algorithms feed us more of what we want - or what we think we want. That reinforces filter bubbles and can limit exposure to challenging or diverse perspectives. In fact, Papacharissi notes that despite interactivity, “the discourse is still dominated by a few” and often reflects existing political hierarchies rather than disrupting them. Exposing a person to the same content on repeat could be detrimental to their own personal development, therefore, I think that in a general sense, a more ethical algorithm might intentionally expose users to unfamiliar ideas, even at the cost of engagement. For instance, within the context of the Israel-Palestine war, many people are being fed content which solely caters towards their own personal narrative of the war. I believe that intelligent people should be aware that there are at least two sides to every story, therefore, an ethical algorithm for my ideal ethical internet would be one which presents users with personalised content, but with the inclusion of varying perspectives for the purpose of education and empowerment. The Pew Research Center (2020) found that most Americans—about 64%—think social media has a mostly negative effect on how things are going in the country, especially when it comes to politics. Many people feel that these platforms spread false information, encourage arguments, and make political divisions worse. This backs up the idea that while the internet could be a space for learning and connection, it often ends up doing the opposite because the systems behind it are built to keep us engaged, not informed.
                    </p>

                    <h3>Pockets of Hope: What an Ethical Internet Could Look Like</h3>
                    <p>
                        Despite the unfortunate reality of the current state of the internet, I've seen glimpses of what a more ethical internet might look like: in game modding communities, open-source projects, or crowdfunding platforms like Kickstarter. These are spaces where people gather to share, collaborate, and create value for one another - not just for advertisers or shareholders. They show that a healthier and more ethical internet isn't impossible - just difficult. Like Silverstone, Orgad suggests we must stop “mistaking connection for closeness, and closeness for commitment”. Being online doesn't automatically make us responsible participants - we have to choose that role.
                        In the end, an ethical internet will never be purely technological. It must be social, cultural, and moral. It should strive for fairness, empathy, transparency, and above all, care. We may never reach the ideal - but it's worth striving toward anyway.
                    </p>

                    <h3>References:</h3>
                    <ul>
                        <li><cite>Orgad, S., 2007. The internet as a moral space: the legacy of Roger Silverstone. New Media & Society, 9(1), pp.33-41.<a class="u-url" href="https://doi.org/10.1177/1461444807075202">The Internet as a Moral Space</a> </cite></li>
                        <li><cite>Papacharissi, Z., 2002. The virtual sphere: the internet as a public sphere. New Media & Society, 4(1), pp.9-27. <a class="u-url" href="https://doi.org/10.1177/14614440222226244">The Virtual Sphere</a></cite></li>
                        <li><cite>Stein, L., 2008. Speech without rights: The status of public space on the internet. The Communication Review, 11(1), pp.1-23.<a class="u-url" href="https://doi.org/10.1080/10714420801888385">Speech Without Rights</a></cite></li>
                        <li><cite>Pew Research Center, 2020. Americans see social media's impact on politics as a negative. [online] Pew Research Center: Internet, Science & Tech. Available at: <a class="u-url" href="https://www.pewresearch.org/internet/2020/10/15/americans-see-social-medias-impact-on-politics-as-negative/ ">Pew Research Center</a></cite></li>
                    </ul>
                </div>
            </article>
        
        </section>

        <a id="nextBtn" class="nav-button">Next</a>
        <a id="prevBtn" class="nav-button">Previous</a>
        

        <button id="backToTopBtn" aria-label="Back to top">↑</button>
    </main>

    <footer>
        &#169 2025. All Rights Reserved. Tal Peretz
    </footer>
</body>

</html>